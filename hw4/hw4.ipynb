{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "dui = pd.read_csv('data/dui.csv')\n",
    "dui['Fatality'].where(dui['Fatality']<=0, 1, True)\n",
    "gender = dui.iloc[:,1]\n",
    "le = LabelEncoder()\n",
    "le.fit(gender)\n",
    "encoded_column = le.transform(gender)\n",
    "dui['Gender'] = encoded_column\n",
    "X = dui.iloc[:,:-1]\n",
    "y = dui.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5628\n",
      "2690\n"
     ]
    }
   ],
   "source": [
    "print(len(dui[dui['Fatality']==0]))\n",
    "print(len(dui[dui['Fatality']==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4501\n",
      "2153\n",
      "1127\n",
      "537\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train[y_train==0]))\n",
    "print(len(y_train[y_train==1]))\n",
    "print(len(y_test[y_test==0]))\n",
    "print(len(y_test[y_test==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dui_test = pd.read_csv('data/dui-test.csv')\n",
    "# dui_test['Fatality'].where(dui_test['Fatality']<=0, 1, True)\n",
    "# gender_test = dui_test.iloc[:,1]\n",
    "# le_test = LabelEncoder()\n",
    "# le_test.fit(gender_test)\n",
    "# encoded_column_test = le_test.transform(gender_test)\n",
    "# dui_test['Gender'] = encoded_column_test\n",
    "# X_test = dui_test.iloc[:,0:-1]\n",
    "# y_test = dui_test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(class_weight={0:0.68, 1:0.32})\n",
    "lr.fit(X_train, y_train)\n",
    "predictions = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8671875\n",
      "Confusion matrixe:\n",
      "      0    1\n",
      "0  995  132\n",
      "1   89  448\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', lr.score(X_test, y_test))\n",
    "print('Confusion matrixe:\\n', pd.DataFrame(confusion_matrix(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'criterion': ('entropy', 'gini'), 'max_depth': [2, 3, 4, 5, 6]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "folds = 10\n",
    "grid_params = {'criterion':('entropy', 'gini'), 'max_depth':[2,3,4,5,6]}\n",
    "classifier = GridSearchCV(dt, grid_params, cv=folds)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  0.8918106686701728 \n",
      "Best Tree:  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n"
     ]
    }
   ],
   "source": [
    "print('Best score: ', classifier.best_score_, '\\nBest Tree: ', classifier.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = classifier.best_estimator_\n",
    "predictions = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9014423076923077\n",
      "Confusion matrixe:\n",
      "       0    1\n",
      "0  1005  122\n",
      "1    42  495\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', dt.score(X_test, y_test))\n",
    "print('Confusion matrixe:\\n', pd.DataFrame(confusion_matrix(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'criterion': ('entropy', 'gini'), 'max_depth': [2, 3, 4, 5, 6]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "folds = 10\n",
    "grid_params = {'criterion':('entropy', 'gini'), 'max_depth':[2,3,4,5,6]}\n",
    "classifier = GridSearchCV(rf, grid_params, cv=folds)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  0.8918106686701728 \n",
      "Best Tree:  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print('Best score: ', classifier.best_score_, '\\nBest Tree: ', classifier.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = classifier.best_estimator_\n",
    "predictions = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9014423076923077\n",
      "Confusion matrixe:\n",
      "       0    1\n",
      "0  1005  122\n",
      "1    42  495\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', rf.score(X_test, y_test))\n",
    "print('Confusion matrixe:\\n', pd.DataFrame(confusion_matrix(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'learning_rate': [1, 0.01, 0.001, 0.0001]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ab = AdaBoostClassifier()\n",
    "folds = 10\n",
    "grid_params = {'learning_rate':[0.01, 0.001, 0.0001]}\n",
    "classifier = GridSearchCV(ab, grid_params, cv=folds)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  0.8851990984222389 \n",
      "Best Tree:  AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=0.01, n_estimators=50, random_state=None)\n"
     ]
    }
   ],
   "source": [
    "print('Best score: ', classifier.best_score_, '\\nBest Tree: ', classifier.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = classifier.best_estimator_\n",
    "predictions = ab.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9014423076923077\n",
      "Confusion matrixe:\n",
      "       0    1\n",
      "0  1005  122\n",
      "1    42  495\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', ab.score(X_test, y_test))\n",
    "print('Confusion matrixe:\\n', pd.DataFrame(confusion_matrix(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_sampl...      subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'learning_rate': [0.1, 0.001, 0.0001], 'max_depth': [2, 3, 4, 5, 6]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "folds = 10\n",
    "grid_params = {'learning_rate':[0.1, 0.001, 0.0001], 'max_depth':[2,3,4,5,6]}\n",
    "classifier = GridSearchCV(gb, grid_params, cv=folds)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  0.8916604057099925 \n",
      "Best Tree:  GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=2,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=None,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print('Best score: ', classifier.best_score_, '\\nBest Tree: ', classifier.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = classifier.best_estimator_\n",
    "predictions = gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9014423076923077\n",
      "Confusion matrixe:\n",
      "       0    1\n",
      "0  1005  122\n",
      "1    42  495\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', gb.score(X_test, y_test))\n",
    "print('Confusion matrixe:\\n', pd.DataFrame(confusion_matrix(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X_train_knn, X_val_knn, y_train_knn, y_val_knn = train_test_split(X_train, y_train, test_size=0.33)\n",
    "\n",
    "results = []\n",
    "for k in range(1, 50):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_knn, y_train_knn)\n",
    "    results.append([k, knn.score(X_val_knn, y_val_knn)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0.8279472007282658],\n",
       " [2, 0.8033682294037323],\n",
       " [3, 0.837960855712335],\n",
       " [4, 0.8152025489303596],\n",
       " [5, 0.8229403732362313],\n",
       " [6, 0.8088302230314065],\n",
       " [7, 0.8142922166590806],\n",
       " [8, 0.8042785616750113],\n",
       " [9, 0.810195721438325],\n",
       " [10, 0.8015475648611743],\n",
       " [11, 0.8097405553026855],\n",
       " [12, 0.7928994082840237],\n",
       " [13, 0.8024578971324533],\n",
       " [14, 0.7947200728265817],\n",
       " [15, 0.8097405553026855],\n",
       " [16, 0.8015475648611743],\n",
       " [17, 0.8070095584888485],\n",
       " [18, 0.8056440600819299],\n",
       " [19, 0.8038233955393719],\n",
       " [20, 0.8042785616750113],\n",
       " [21, 0.812016385980883],\n",
       " [22, 0.8106508875739645],\n",
       " [23, 0.8161128812016386],\n",
       " [24, 0.812926718252162],\n",
       " [25, 0.8192990441511152],\n",
       " [26, 0.8161128812016386],\n",
       " [27, 0.8161128812016386],\n",
       " [28, 0.8142922166590806],\n",
       " [29, 0.8161128812016386],\n",
       " [30, 0.8088302230314065],\n",
       " [31, 0.8233955393718707],\n",
       " [32, 0.809285389167046],\n",
       " [33, 0.8170232134729176],\n",
       " [34, 0.811106053709604],\n",
       " [35, 0.8170232134729176],\n",
       " [36, 0.812926718252162],\n",
       " [37, 0.815657715065999],\n",
       " [38, 0.809285389167046],\n",
       " [39, 0.8174783796085571],\n",
       " [40, 0.8051888939462903],\n",
       " [41, 0.812016385980883],\n",
       " [42, 0.8097405553026855],\n",
       " [43, 0.8115612198452435],\n",
       " [44, 0.8042785616750113],\n",
       " [45, 0.8115612198452435],\n",
       " [46, 0.7942649066909422],\n",
       " [47, 0.7983614019116978],\n",
       " [48, 0.7924442421483842],\n",
       " [49, 0.7960855712335002]]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "predictions = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8407451923076923\n",
      "Confusion matrixe:\n",
      "      0    1\n",
      "0  985  142\n",
      "1  123  414\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', knn.score(X_test, y_test))\n",
    "print('Confusion matrixe:\\n', pd.DataFrame(confusion_matrix(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.001, max_delta_step=0,\n",
       "       max_depth=2, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'learning_rate': [0.1, 0.001, 0.0001], 'max_depth': [1, 2, 3, 4, 5, 6]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(learning_rate=0.001, max_depth=2)\n",
    "folds = 5\n",
    "grid_params = {'learning_rate':[0.1, 0.001, 0.0001], 'max_depth':[1,2,3,4,5,6]}\n",
    "classifier = GridSearchCV(xgb, grid_params, cv=folds)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  0.8922614575507137 \n",
      "Best Tree:  XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.001, max_delta_step=0,\n",
      "       max_depth=5, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n"
     ]
    }
   ],
   "source": [
    "print('Best score: ', classifier.best_score_, '\\nBest Tree: ', classifier.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = classifier.best_estimator_\n",
    "predictions = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8960336538461539\n",
      "Confusion matrixe:\n",
      "       0    1\n",
      "0  1001  126\n",
      "1    47  490\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', xgb.score(X_test, y_test))\n",
    "print('Confusion matrixe:\\n', pd.DataFrame(confusion_matrix(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mc = MLPClassifier(hidden_layer_sizes=(200,100,), learning_rate_init=0.001, solver='adam', activation='logistic')\n",
    "mc.fit(X_train, y_train)\n",
    "predictions = mc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.875\n",
      "Confusion matrixe:\n",
      "       0    1\n",
      "0  1026  101\n",
      "1   107  430\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', mc.score(X_test, y_test))\n",
    "print('Confusion matrixe:\\n', pd.DataFrame(confusion_matrix(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
